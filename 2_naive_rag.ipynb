{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6550d0b7-3486-4f5a-8f06-0451afe8998e",
   "metadata": {
    "name": "naive_rag",
    "collapsed": false,
    "resultHeight": 183
   },
   "source": "# Část 2\nNyní zkusíme využít oklasifikované události z předchozí části a upravit jimi znalostní bázi našeho LLM modelu.\n\nNezapomeňte si opět nainstalovat balíček _snowflake-ml-python_ z tlačítka _Packages_ v horní liště."
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "resultHeight": 0
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\nfrom snowflake.snowpark.functions import col\n\nfrom snowflake.cortex import Complete, CompleteOptions\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b547aa14-2efd-4e39-b1b5-f2e5b96d35f2",
   "metadata": {
    "language": "python",
    "name": "helper_functions",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "# Pomocne fce\nimport json\nimport random\n\n# Pomocna funkce na prevedeni radku do JSON formatu\ndef jsonify_row(row):\n    return json.dumps(row.as_dict(), indent=2, ensure_ascii=False)\n\n\n# Ocisteni uzivatelskeho jmena\ndef user_suffix(session):\n    if name := session.get_current_user():\n        return name[1:-1]\n    # nemelo by nastat, ale at mame string\n    return f\"NONE_{random.randint(1,1000)}\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "36a6107d-b7c0-4db1-ba49-f8b4276adeac",
   "metadata": {
    "language": "python",
    "name": "cell2",
    "resultHeight": 0
   },
   "outputs": [],
   "source": "model = \"llama3.1-70b\"\nuser_tables_suffix = user_suffix(session)\ncategorization_table = f\"EVENT_CATEGORIZATION_{user_tables_suffix}\"\n\ndf_categorization = session.read.table(categorization_table)\ndf_test_questions = session.read.table(\"TEST_2024\")\ntest_q_collected = df_test_questions.collect()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1d9dea1c-a401-4b8b-b0c6-5fddf44dd0ae",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "resultHeight": 422
   },
   "outputs": [],
   "source": "st.dataframe(df_test_questions)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ebbe07d6-1054-44ed-87a8-096e9741be1d",
   "metadata": {
    "language": "python",
    "name": "cell3",
    "resultHeight": 0
   },
   "outputs": [],
   "source": "def get_random_test_question():\n    idx = random.randint(0, len(test_q_collected) - 1)\n    return test_q_collected[idx]\n\n\ndef get_question(idx):\n    return test_q_collected[idx]",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c61ac041-eb54-4641-a681-ffedcd463c8d",
   "metadata": {
    "language": "python",
    "name": "cell5",
    "resultHeight": 104
   },
   "outputs": [],
   "source": "# Zkuste si, jake odpovedi nam dava model na otazky z roku 2024\n# Experimentujte take s parametrem temperature\n\nquestion = get_random_test_question()  # Nebo si ulozte jednu predem a upravujte temperature\nquestion = get_question(1)\n\nsystem_prompt = \"You are an assistant specialized in history. Provide short and accurate answers to user's questions.\"\nuser_prompt = question.Q_TEXT\nexpected_answer = question.Q_ANSWER\n\noptions = CompleteOptions(temperature=0.8)\n\nclassification = Complete(\n    model,\n    [\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": user_prompt},\n    ],\n    options=options\n)\n\nprint(f\"\"\"Question to model: {user_prompt}\nExpected answer: {expected_answer}\nModel answer: {classification}\n\"\"\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a0e7c464-2c3f-41ca-8c1e-e6382505f5df",
   "metadata": {
    "language": "sql",
    "name": "cell6",
    "resultHeight": 111
   },
   "outputs": [],
   "source": "-- Mimochodem ve Snowflake noteboocich je mozne kombinovat Python a SQL\n-- Volani Complete fce v SQL muze vypadat treba takto\nSELECT SNOWFLAKE.CORTEX.COMPLETE(\n    'llama3.1-8b',\n    ARRAY_CONSTRUCT(\n        OBJECT_CONSTRUCT(\n            'role', 'system', \n            'content', 'You are a helpful assisstant trying to answer user''s questions'),\n        OBJECT_CONSTRUCT(\n            'role', 'user', \n            'content', 'When is your trainig data cut-off?')\n    ),\n    OBJECT_CONSTRUCT(\n        'temperature', 0.1\n    )\n);",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2625899e-5984-47ea-868f-250c32b53f3e",
   "metadata": {
    "name": "cell8",
    "collapsed": false,
    "resultHeight": 169
   },
   "source": "## Úloha - naivní RAG\nA nyní zkusíme využít námi oklasifikované události z roku 2024, abychom rozšířili znalosti námi používaného LLM modelu.\n\nV první fázi zkusíme, jestli dostaneme očekávané výsledky na události z roku 2024 ve sportovní kategorii."
  },
  {
   "cell_type": "code",
   "id": "ef7f4b78-7da5-4610-8d30-35d87a620b95",
   "metadata": {
    "language": "python",
    "name": "cell7",
    "resultHeight": 0
   },
   "outputs": [],
   "source": "only_sport_q = df_test_questions.filter(col(\"CATEGORY_ID\") == 2)\nonly_sport_events = df_categorization.filter(col(\"CATEGORY_ID\") == 2)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "55901d3e-6e41-4f1b-82d7-05c294bba13a",
   "metadata": {
    "language": "python",
    "name": "cell11",
    "resultHeight": 216
   },
   "outputs": [],
   "source": "only_sport_events",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "21fef5b8-efc3-46b0-9c37-d329ab3d1f17",
   "metadata": {
    "language": "python",
    "name": "cell13",
    "resultHeight": 0
   },
   "outputs": [],
   "source": "info = \"/n\".join(jsonify_row(r) for r in only_sport_events.select(\"EVENT_TEXT\").collect())\n\nsystem_prompt = f\"\"\"You are a helpful assistant. Use short answers, at most 5 words long. When answering user's question, use following information (each information is a JSON object with element EVENT_TEXT describing the event):\n{info}\n\"\"\"\n\n# Klasiciky si zkuste i ruzne hodnoty temperature\noptions = CompleteOptions(temperature=0.1)\n\nsports_list = []\nfor row in only_sport_q.collect():\n    answer = Complete(\n        model,\n        [\n            {\"role\": \"system\", \"content\": system_prompt},\n            {\"role\": \"user\", \"content\": row.Q_TEXT},\n        ],\n        options=options\n    )\n    sports_list.append(\n        [row.Q_TEXT, row.Q_ANSWER, answer]\n    )\n\nsport_df = session.create_dataframe(sports_list, [\"question\", \"expected\", \"llm_answer\"])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ec193043-d9ec-476a-9a5d-e977001cb9ab",
   "metadata": {
    "language": "python",
    "name": "cell17",
    "resultHeight": 340
   },
   "outputs": [],
   "source": "st.dataframe(sport_df)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "25c53b8b-8276-421a-bfc7-b3e5def10585",
   "metadata": {
    "name": "cell9",
    "collapsed": false,
    "resultHeight": 252
   },
   "source": "Nyní se pokuste seskládat všechny výše použité kódy k tomu, abyste sestavili _vyhodnocovacího agenta_. Ten bude mít podobu funkce (viz níže), která na vstupu dostane uživatelský prompt. Našim cílem bude kategorizovat uživatelovu otázku, na základě toho vybrat události pouze z relevantní kategorie a následně odpovědět.\n\nPokud uživatel zadá otázku mimo naše 4 kategorie, buď mu řekněte, že na takové otázky neodpovídáte, nebo nechcte odpovědět LLM bez poskytnutí znalostní báze.\n\n\\* Pozn.: Kontextové okno llamy je dost velké, aby se do něj vešly všechny naše kategorizované události. Toto řešení ale nechceme ;) "
  },
  {
   "cell_type": "code",
   "id": "41845f99-f9df-4f1d-8823-7a6ffb02c781",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": "def perform_naive_rag(user_prompt: str) -> str:\n    # Faze 1 - kategorizujme uzivatelovu otazku\n    system_prompt_1 = \"Classify user prompt...\"\n    category = Complete(...)  # mozna bude nutne jeste nejak transformovat\n\n    # Vybereme kategorii znalostni baze dle klasifikace user promptu\n    relevant_documents = (\n        df_categorization\n        .filter(col(\"CATEGORY\") == category)\n    )\n\n    system_prompt_2 = \"...\"   \n    # Odpovime na uzivatelovu otazku\n    answer = Complete(...)\n    \n    return answer",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c154ac75-291f-4829-8f48-08b07d7d87d1",
   "metadata": {
    "language": "python",
    "name": "cell14",
    "resultHeight": 0
   },
   "outputs": [],
   "source": "# Vyzkousime si odpovedi ...\ntest_questions = random.sample(df_test_questions.collect(), k=10)\n\nnaive_rag_ans = []\nfor tq in test_questions:\n    llm_answer = perform_naive_rag(tq.Q_TEXT)\n    naive_rag_ans.append([tq.Q_TEXT, tq.Q_ANSWER, llm_answer])\n\nnaive_rag_df = session.create_dataframe(naive_rag_ans, [\"question\", \"expected\", \"llm_answer\"])",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b8511417-1c3f-4d76-8eff-485eedd643fe",
   "metadata": {
    "name": "cell15",
    "collapsed": false,
    "resultHeight": 227
   },
   "source": "V reálné praxi samozřejmě máme znalostní bázi podstatně větší a potřebujeme tedy používat efektivnější metody přístupu k ní. Typicky každý dokument, který chceme zařadit do znalostní báze, rozdělíme na menší části, nad kterými následně spočítáme _embedding_ (transformujeme text do číselného vektoru).\n\nDokumenty včetně embeddingů následně uložíme do _vektorové databáze_, od které očekáváme, že dokáže efektivně vyhledat _n_ nejbližších dokumentů na základě podobnosti _embeddingů_. \n\nV další fázi si tedy zkusíme spočítat embeddingy nad našimi událostmi a vyhledávat mezi nimi na základě našich dotazů."
  },
  {
   "cell_type": "code",
   "id": "ae9f3abb-fcef-4af3-bdfd-ef45735108f7",
   "metadata": {
    "language": "python",
    "name": "cell18",
    "resultHeight": 0
   },
   "outputs": [],
   "source": "from langchain_text_splitters import CharacterTextSplitter\n\n# Snowflake embedding modely maji limit 512 tokenu, takze je potreba nase texty rozdelit\n# Muzete zkusit experimentovat s parametry nebo jinymi splittery\ntext_splitter = CharacterTextSplitter(\n    separator=\"\\n\",\n    chunk_size=400,\n    chunk_overlap=50,\n    length_function=len,\n    is_separator_regex=False,\n)\n\nall_event_texts = df_categorization.select(\"EVENT_TEXT\").collect()\ntexts = text_splitter.create_documents([r.EVENT_TEXT for r in all_event_texts])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "416eee9a-6ee6-4252-913f-f653f0ccc194",
   "metadata": {
    "language": "python",
    "name": "cell16",
    "resultHeight": 0
   },
   "outputs": [],
   "source": "from snowflake.cortex import EmbedText768, EmbedText1024\n\n\n# Zaexperimentujte si s ruznymi modely a delkou vektoru \nembedding_model = \"snowflake-arctic-embed-m\"  \n# embedding_model = \"e5-base-v2\"\n\nvector_table = f\"VECTOR_{user_tables_suffix}\"\n\nchunks_df = session.create_dataframe([t.page_content for t in texts], [\"text\"])\nchunks_embedded = chunks_df.withColumn(\n    \"embedding\", \n    EmbedText768(embedding_model, chunks_df[\"TEXT\"])\n)\nchunks_embedded.write.save_as_table(vector_table, mode='overwrite')\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5ab43152-804f-41ef-804f-b41caa0686a9",
   "metadata": {
    "language": "python",
    "name": "cell26",
    "resultHeight": 0
   },
   "outputs": [],
   "source": "# Vyhledavani podle kosinove vzdalenosti bohuzel jeste neni v Python API, takze si musime \n# pomoct takto:\nuser_query = \"How many states did Kamala Harris win in 2024?\"\nemb_limit = 3\ndf = session.sql(f\"\"\"\n    SELECT\n        t.text,\n        VECTOR_COSINE_SIMILARITY(\n            t.embedding,\n            SNOWFLAKE.CORTEX.EMBED_TEXT_768(\n                ?, \n                ?\n            )\n        ) AS similarity\n    FROM {vector_table} AS t\n    ORDER BY similarity DESC\n    LIMIT {emb_limit}\n    \"\"\",\n    params=[embedding_model, user_query]            \n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b4e97d10-2b57-4b3f-85a8-f0a02ce7f1b5",
   "metadata": {
    "language": "python",
    "name": "cell24",
    "resultHeight": 181
   },
   "outputs": [],
   "source": "df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "537b76c6-1994-49c4-8835-9ac1eacdddfe",
   "metadata": {
    "language": "python",
    "name": "cell19"
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c3c1e7aa-45a7-45ed-acf9-ad753df75bd3",
   "metadata": {
    "name": "cell20",
    "collapsed": false,
    "resultHeight": 108
   },
   "source": "Nyní vytvořte nového agenta analogického k _perform_naive_rag_, který ovšem pro vyhledávání relevantních dokumentů budou používat před chvílí vytvořenou tabulku s embeddingy jednotlivých událostí. \n\nExperimentuje s různými modely, velikostmi embeddingů a počtem dokumentů, které do modelu dodáte."
  },
  {
   "cell_type": "code",
   "id": "b1906c8d-89a4-478d-b3f1-7987c6f33e01",
   "metadata": {
    "language": "python",
    "name": "cell21"
   },
   "outputs": [],
   "source": "def embedding_rag(user_prompt):\n    pass  # Now it's your task ;)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "289391cf-6c93-44d1-9d26-26da62bac31b",
   "metadata": {
    "language": "python",
    "name": "cell22"
   },
   "outputs": [],
   "source": "# Vyzkousime si odpovedi ...\nrag_test_questions = random.sample(df_test_questions.collect(), k=10)\n\nembedding_rag = []\nfor tq in rag_test_questions:\n    llm_answer = perform_naive_rag(tq.Q_TEXT)\n    embedding_rag.append([tq.Q_TEXT, tq.Q_ANSWER, llm_answer])\n\nembedding_rag_df = session.create_dataframe(embedding_rag, [\"question\", \"expected\", \"llm_answer\"])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b7aad528-3253-415f-8b81-43a3e7e8c93b",
   "metadata": {
    "language": "python",
    "name": "cell23"
   },
   "outputs": [],
   "source": "embedding_rag_df.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e4d43d9a-e023-4600-83cb-cba1d751febe",
   "metadata": {
    "name": "cell10",
    "collapsed": false,
    "resultHeight": 428
   },
   "source": "## Bonus\nVytvořte LLM, který _lže_. Vytvořte si vlastní znalostní bázi, která bude obsahovat nepravdivé informace, a pokuste se s jejím využitím nastavit systémový prompt tak, aby model bez zaváhání odpovídal nepravdivě na všeobecně známa historická fakta (přesné otázky si vymyslete sami, nebo si témata nechte vygenerovat ;), ale jako inspiraci dáváme):\n\n- Samostatná Česká republika nevznikla 1.1.1993\n- Prvním člověkem ve vesmíru byl Jára Cimrman\n- Americkou občanskou válku vyhrála Konfederace\n- Richard Nixon vyhrál prezidentské volby už v roce 1960 a J.F. Kennedy tak zůstal až do své smrti roku 2012 řadovým senátorem za Massachusetts\n- Otcem Luka Skywalkera je Obi-Wan Kenobi\n\nZajistěte, aby LLM podávalo odpovědi jako fakta, kterým opravdu věří. Především zamezte tomu, aby odpovídalo stylem \"Podle mé znalostní báze se to sice stalo takhle, ale to je špatně a ve skutečnosti ...\"."
  }
 ]
}